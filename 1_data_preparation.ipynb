{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for All State Kaggle Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Imports\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Routines for two preprocessing options:\n",
    "preProcess1: binarize categorical variables and apply a minimum variance threshold.\n",
    "preProcess2: convert categorical variable labels to integers.\n",
    "'''\n",
    "\n",
    "def preProcess1(df, prob):\n",
    "    \n",
    "    # Make a dictionary of the number of levels for each categorical feature.\n",
    "    catdict  = {key: 0 for key in df.columns.values if key[:3]==\"cat\"}\n",
    "    for var in catdict.keys():\n",
    "        catdict[var] = len(df[var].unique())\n",
    "    print(\"Total number of categorical feature levels: {0}\".format(sum(catdict.values())))\n",
    "\n",
    "    # Binarize categorical features\n",
    "    df = pd.get_dummies( df, drop_first=False)\n",
    "    print(\"Shape of data frame after binarization: {0}\".format(df.shape))\n",
    "\n",
    "    # Eliminate binary features for which the minority label appears \n",
    "    # in a fraction less than prob of instances\n",
    "    cats     = [feature for feature in df.columns.values if feature[:3]==\"cat\"]\n",
    "    conts    = [feature for feature in df.columns.values if feature[:4]==\"cont\"]\n",
    "    binvar   = prob * (1.0-prob)\n",
    "    sel      = VarianceThreshold(threshold=binvar)\n",
    "    sel.fit(df[cats])\n",
    "    retain   = sel.get_support(indices=True)\n",
    "    features = [cats[ind] for ind in retain] + conts + [\"loss\"]\n",
    "    df       = df[features]\n",
    "    print(\"Shape of data frame after variance filter: {0}\".format(df.shape))\n",
    "\n",
    "    # Eliminate one dummy binary per category not affected by the low-variance filter.\n",
    "    remove = []\n",
    "    for key,nlevels in catdict.items():\n",
    "        binlist = [feature for feature in features if key+\"_\" in feature]\n",
    "        if len(binlist) == nlevels:\n",
    "            remove.append(binlist[0])\n",
    "    keep = [feature for feature in features if feature not in remove]\n",
    "    df = df[keep]\n",
    "    print(\"Shape of data frame after dummy elimination: {0}\\n\".format(df.shape))\n",
    "    \n",
    "    # Done\n",
    "    return df\n",
    "\n",
    "def preProcess2(df):\n",
    "    \n",
    "    # Convert categorical variable labels to integers.\n",
    "    df.iloc[:,:116] = df.iloc[:,:116].apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    # Done\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data frame: (188318, 131)\n",
      "Shape of testing data frame:  (125546, 130)\n",
      "Shape of combined data frame: (313864, 131)\n",
      "Total number of categorical feature levels: 1176\n",
      "Shape of data frame after binarization: (313864, 1191)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load and preprocess the AllState data. Each row consists of one index, \n",
    "116 categorical predictors, 14 continuous predictors, and (in the case \n",
    "of the training data) one continuous response variable called loss.\n",
    "\n",
    "Note that we combine train and test data before doing the preprocessing.\n",
    "This is to avoid problems with categorical variables that have labels\n",
    "appearing in one set but not in the other. Binarizing or integerizing \n",
    "such variables would lead to label confusion across sets.\n",
    "'''\n",
    "\n",
    "# Choose preprocessing options:\n",
    "preProc = 1\n",
    "prob    = 0.05\n",
    "assert preProc==1 or preProc==2, \"Invalid preprocessing option\"\n",
    "assert preProc==2 or (prob>=0.0 and prob<=1.0), \"Invalid probability value\"\n",
    "\n",
    "# Read entire training and testing data sets, and combine them for preprocessing purposes.\n",
    "# But first reshuffle training set to avoid bias when we split it into training/validation/testing subsets.\n",
    "dfa = pd.read_csv(\"data/train.csv\", delimiter=\",\", header=0, index_col=0, nrows=None)\n",
    "dfaLength = len(dfa)\n",
    "df0 = dfa.sample(n=dfaLength, replace=False, weights=None, random_state=123, axis=0)\n",
    "df0Length = len(df0)\n",
    "print('Shape of training data frame: {0}'.format(df0.shape))\n",
    "df1 = pd.read_csv(\"data/test.csv\", delimiter=\",\", header=0, index_col=0, nrows=None)\n",
    "df1Length = len(df1)\n",
    "print('Shape of testing data frame:  {0}'.format(df1.shape))\n",
    "df1.loc[:,'loss'] = pd.Series([-1.0]*df1Length, index=df1.index)\n",
    "df2 = df0.append(df1)\n",
    "print('Shape of combined data frame: {0}'.format(df2.shape))\n",
    "\n",
    "# Do the preprocessing\n",
    "if preProc==1:\n",
    "    df2 = preProcess1(df2, prob)\n",
    "elif preProc==2:\n",
    "    df2 = preProcess2(df2)\n",
    "    \n",
    "# Split data frame back into training and test sets\n",
    "df0, df1 = df2.iloc[:df0Length,:], df2.iloc[df0Length:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data frame saved to data/train_prep1_prob010.pkl\n",
      "Testing data frame saved to data/test_prep1_prob010.pkl\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Save preprocessed data frames\n",
    "'''\n",
    "if preProc==1:\n",
    "    train_fname = 'data/train_prep1_prob{0:03d}.pkl'.format(int(1000*prob))\n",
    "else:\n",
    "    train_fname = 'data/train_prep2.pkl'\n",
    "try:\n",
    "    df0.to_pickle(train_fname)\n",
    "    print('Training data frame saved to {0}'.format(train_fname))\n",
    "except:\n",
    "    print('Error saving training data frame to {0}'.format(train_fname))\n",
    "\n",
    "test_fname = train_fname.replace('train', 'test')\n",
    "try:\n",
    "    df1.to_pickle(test_fname)\n",
    "    print('Testing data frame saved to {0}'.format(test_fname))\n",
    "except:\n",
    "    print('Error saving testing data frame to {0}'.format(test_fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
