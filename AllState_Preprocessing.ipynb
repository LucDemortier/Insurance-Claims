{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data frame: (188318, 131)\n",
      "\n",
      "Total number of categorical feature levels: 1139\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load the AllState training data.\n",
    "Each row consists of one index, 116 categorical predictors, 14 continuous \n",
    "predictors, and one continuous response variable called loss.\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df0 = pd.read_csv(\"data/train.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "print(\"Shape of training data frame: %s\\n\" %(df0.shape,))\n",
    "\n",
    "# Make a dictionary of the number of levels for each categorical feature.\n",
    "catdict  = {\"cat{0}\".format(ind): 0 for ind in range(1,117)}\n",
    "for var in catdict.keys():\n",
    "    catdict[var] = len(df0[var].unique())\n",
    "print(\"Total number of categorical feature levels: {0}\".format(sum(catdict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of converted data frame: (188318, 1154)\n",
      "\n",
      "Converted data frame head:        cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n",
      "id                                                                         \n",
      "1   0.726300  0.245921  0.187583  0.789639  0.310061  0.718367  0.335060   \n",
      "2   0.330514  0.737068  0.592681  0.614134  0.885834  0.438917  0.436585   \n",
      "5   0.261841  0.358319  0.484196  0.236924  0.397069  0.289648  0.315545   \n",
      "10  0.321594  0.555782  0.527991  0.373816  0.422268  0.440945  0.391128   \n",
      "11  0.273204  0.159990  0.527991  0.473202  0.704268  0.178193  0.247408   \n",
      "\n",
      "      cont8    cont9   cont10    ...     cat116_P  cat116_Q  cat116_R  \\\n",
      "id                               ...                                    \n",
      "1   0.30260  0.67135  0.83510    ...            0         0         0   \n",
      "2   0.60087  0.35127  0.43919    ...            0         0         0   \n",
      "5   0.27320  0.26076  0.32446    ...            0         0         0   \n",
      "10  0.31796  0.32128  0.44467    ...            0         0         0   \n",
      "11  0.24564  0.22089  0.21230    ...            0         0         0   \n",
      "\n",
      "    cat116_S  cat116_T  cat116_U  cat116_V  cat116_W  cat116_X  cat116_Y  \n",
      "id                                                                        \n",
      "1          0         0         0         0         0         0         0  \n",
      "2          0         0         0         0         0         0         0  \n",
      "5          0         0         0         0         0         0         0  \n",
      "10         0         0         0         0         0         0         0  \n",
      "11         0         0         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 1154 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Convert categorical variables into subsets of binary ones.\n",
    "Postpone the dropping of one binary per category until after the low-variance variable removal.\n",
    "'''\n",
    "df1 = pd.get_dummies( df0, drop_first=False)\n",
    "print(\"Shape of converted data frame: {0}\".format(df1.shape))\n",
    "print(\"\\nConverted data frame head: {0}\".format(df1.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of reduced data frame: (188318, 194)\n",
      "\n",
      "List of remaining features (df2): \n",
      "['cat1_A' 'cat1_B' 'cat2_A' 'cat2_B' 'cat3_A' 'cat3_B' 'cat4_A' 'cat4_B'\n",
      " 'cat5_A' 'cat5_B' 'cat6_A' 'cat6_B' 'cat8_A' 'cat8_B' 'cat9_A' 'cat9_B'\n",
      " 'cat10_A' 'cat10_B' 'cat11_A' 'cat11_B' 'cat12_A' 'cat12_B' 'cat13_A'\n",
      " 'cat13_B' 'cat23_A' 'cat23_B' 'cat25_A' 'cat25_B' 'cat26_A' 'cat26_B'\n",
      " 'cat27_A' 'cat27_B' 'cat36_A' 'cat36_B' 'cat37_A' 'cat37_B' 'cat38_A'\n",
      " 'cat38_B' 'cat44_A' 'cat44_B' 'cat50_A' 'cat50_B' 'cat53_A' 'cat53_B'\n",
      " 'cat71_A' 'cat71_B' 'cat72_A' 'cat72_B' 'cat73_A' 'cat73_B' 'cat75_A'\n",
      " 'cat75_B' 'cat79_B' 'cat79_D' 'cat80_B' 'cat80_D' 'cat81_B' 'cat81_D'\n",
      " 'cat82_A' 'cat82_B' 'cat82_D' 'cat83_A' 'cat83_B' 'cat83_D' 'cat84_A'\n",
      " 'cat84_C' 'cat86_B' 'cat86_C' 'cat86_D' 'cat87_B' 'cat87_D' 'cat88_A'\n",
      " 'cat88_D' 'cat90_A' 'cat90_B' 'cat91_A' 'cat91_B' 'cat91_G' 'cat92_A'\n",
      " 'cat92_H' 'cat93_C' 'cat93_D' 'cat94_B' 'cat94_C' 'cat94_D' 'cat95_C'\n",
      " 'cat95_D' 'cat95_E' 'cat96_E' 'cat97_A' 'cat97_C' 'cat97_E' 'cat97_G'\n",
      " 'cat98_A' 'cat98_C' 'cat98_D' 'cat98_E' 'cat99_P' 'cat99_R' 'cat99_T'\n",
      " 'cat100_F' 'cat100_G' 'cat100_H' 'cat100_I' 'cat100_J' 'cat100_K'\n",
      " 'cat100_L' 'cat101_A' 'cat101_C' 'cat101_D' 'cat101_F' 'cat101_G'\n",
      " 'cat102_A' 'cat103_A' 'cat103_B' 'cat103_C' 'cat104_D' 'cat104_E'\n",
      " 'cat104_F' 'cat104_G' 'cat104_H' 'cat104_I' 'cat104_K' 'cat105_D'\n",
      " 'cat105_E' 'cat105_F' 'cat105_G' 'cat105_H' 'cat106_E' 'cat106_F'\n",
      " 'cat106_G' 'cat106_H' 'cat106_I' 'cat106_J' 'cat107_E' 'cat107_F'\n",
      " 'cat107_G' 'cat107_H' 'cat107_I' 'cat107_J' 'cat107_K' 'cat108_B'\n",
      " 'cat108_D' 'cat108_F' 'cat108_G' 'cat108_K' 'cat109_AB' 'cat109_BI'\n",
      " 'cat110_BT' 'cat110_CL' 'cat110_CO' 'cat110_CS' 'cat110_EB' 'cat110_EG'\n",
      " 'cat111_A' 'cat111_C' 'cat111_E' 'cat112_AH' 'cat112_AS' 'cat112_E'\n",
      " 'cat112_J' 'cat113_AE' 'cat113_AX' 'cat113_BM' 'cat113_L' 'cat113_Y'\n",
      " 'cat114_A' 'cat114_C' 'cat114_E' 'cat115_J' 'cat115_K' 'cat115_L'\n",
      " 'cat115_M' 'cat115_N' 'cat115_O' 'cat115_P' 'cat116_CK' 'cat116_DJ'\n",
      " 'cat116_HK' 'cont1' 'cont2' 'cont3' 'cont4' 'cont5' 'cont6' 'cont7'\n",
      " 'cont8' 'cont9' 'cont10' 'cont11' 'cont12' 'cont13' 'cont14' 'loss']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Eliminate categorical features with low variance.\n",
    "'''\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "cats     = [feature for feature in df1.columns.values if feature[:3]==\"cat\"]\n",
    "conts    = [feature for feature in df1.columns.values if feature[:4]==\"cont\"]\n",
    "prob     = 0.95\n",
    "binvar   = prob * (1.0-prob)\n",
    "sel      = VarianceThreshold(threshold=binvar)\n",
    "sel.fit(df1[cats])\n",
    "retain   = sel.get_support(indices=True)\n",
    "features = [cats[ind] for ind in retain] + conts + [\"loss\"]\n",
    "df2      = df1[features]\n",
    "print(\"\\nShape of reduced data frame: {0}\".format(df2.shape))\n",
    "print(\"\\nList of remaining features (df2): \\n{0}\".format(df2.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of reduced data frame: (188318, 170)\n",
      "\n",
      "List of remaining features (df2): \n",
      "['cat1_B' 'cat2_B' 'cat3_B' 'cat4_B' 'cat5_B' 'cat6_B' 'cat8_B' 'cat9_B'\n",
      " 'cat10_B' 'cat11_B' 'cat12_B' 'cat13_B' 'cat23_B' 'cat25_B' 'cat26_B'\n",
      " 'cat27_B' 'cat36_B' 'cat37_B' 'cat38_B' 'cat44_B' 'cat50_B' 'cat53_B'\n",
      " 'cat71_B' 'cat72_B' 'cat73_A' 'cat73_B' 'cat75_A' 'cat75_B' 'cat79_B'\n",
      " 'cat79_D' 'cat80_B' 'cat80_D' 'cat81_B' 'cat81_D' 'cat82_A' 'cat82_B'\n",
      " 'cat82_D' 'cat83_A' 'cat83_B' 'cat83_D' 'cat84_A' 'cat84_C' 'cat86_B'\n",
      " 'cat86_C' 'cat86_D' 'cat87_B' 'cat87_D' 'cat88_A' 'cat88_D' 'cat90_A'\n",
      " 'cat90_B' 'cat91_A' 'cat91_B' 'cat91_G' 'cat92_A' 'cat92_H' 'cat93_C'\n",
      " 'cat93_D' 'cat94_B' 'cat94_C' 'cat94_D' 'cat95_C' 'cat95_D' 'cat95_E'\n",
      " 'cat96_E' 'cat97_A' 'cat97_C' 'cat97_E' 'cat97_G' 'cat98_A' 'cat98_C'\n",
      " 'cat98_D' 'cat98_E' 'cat99_P' 'cat99_R' 'cat99_T' 'cat100_F' 'cat100_G'\n",
      " 'cat100_H' 'cat100_I' 'cat100_J' 'cat100_K' 'cat100_L' 'cat101_A'\n",
      " 'cat101_C' 'cat101_D' 'cat101_F' 'cat101_G' 'cat102_A' 'cat103_A'\n",
      " 'cat103_B' 'cat103_C' 'cat104_D' 'cat104_E' 'cat104_F' 'cat104_G'\n",
      " 'cat104_H' 'cat104_I' 'cat104_K' 'cat105_D' 'cat105_E' 'cat105_F'\n",
      " 'cat105_G' 'cat105_H' 'cat106_E' 'cat106_F' 'cat106_G' 'cat106_H'\n",
      " 'cat106_I' 'cat106_J' 'cat107_E' 'cat107_F' 'cat107_G' 'cat107_H'\n",
      " 'cat107_I' 'cat107_J' 'cat107_K' 'cat108_B' 'cat108_D' 'cat108_F'\n",
      " 'cat108_G' 'cat108_K' 'cat109_AB' 'cat109_BI' 'cat110_BT' 'cat110_CL'\n",
      " 'cat110_CO' 'cat110_CS' 'cat110_EB' 'cat110_EG' 'cat111_A' 'cat111_C'\n",
      " 'cat111_E' 'cat112_AH' 'cat112_AS' 'cat112_E' 'cat112_J' 'cat113_AE'\n",
      " 'cat113_AX' 'cat113_BM' 'cat113_L' 'cat113_Y' 'cat114_A' 'cat114_C'\n",
      " 'cat114_E' 'cat115_J' 'cat115_K' 'cat115_L' 'cat115_M' 'cat115_N'\n",
      " 'cat115_O' 'cat115_P' 'cat116_CK' 'cat116_DJ' 'cat116_HK' 'cont1' 'cont2'\n",
      " 'cont3' 'cont4' 'cont5' 'cont6' 'cont7' 'cont8' 'cont9' 'cont10' 'cont11'\n",
      " 'cont12' 'cont13' 'cont14' 'loss']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Eliminate one dummy binary per category not affected by the low-variance variable removal.\n",
    "'''\n",
    "remove = []\n",
    "for key,nlevels in catdict.items():\n",
    "    binlist = [feature for feature in features if key+\"_\" in feature]\n",
    "    if len(binlist) == nlevels:\n",
    "        remove.append(binlist[0])\n",
    "keep = [feature for feature in features if feature not in remove]\n",
    "df2 = df2[keep]\n",
    "print(\"\\nShape of reduced data frame: {0}\".format(df2.shape))\n",
    "print(\"\\nList of remaining features (df2): \\n{0}\".format(df2.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df2 data frame: \n",
      "(188318, 170)\n",
      "\n",
      "Head of df2 data frame: \n",
      "    cat1_B  cat2_B  cat3_B  cat4_B  cat5_B  cat6_B  cat8_B  cat9_B  cat10_B  \\\n",
      "id                                                                            \n",
      "1        0       1       0       1       0       0       0       1        0   \n",
      "\n",
      "    cat11_B    ...        cont6    cont7   cont8    cont9  cont10    cont11  \\\n",
      "id             ...                                                            \n",
      "1         1    ...     0.718367  0.33506  0.3026  0.67135  0.8351  0.569745   \n",
      "\n",
      "      cont12    cont13    cont14   logloss  \n",
      "id                                          \n",
      "1   0.594646  0.822493  0.714843  7.702186  \n",
      "\n",
      "[1 rows x 170 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Replace loss by log-loss.\n",
    "'''\n",
    "df2.loc[:,'logloss'] = np.log(df2.loc[:,'loss'])\n",
    "df2 = df2.drop(['loss'], axis=1)\n",
    "print(\"Shape of df2 data frame: \\n{0}\".format(df2.shape))\n",
    "print(\"\\nHead of df2 data frame: \\n{0}\".format(df2.head(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mutual Informations: [ 0.73119671  1.          0.51198742  0.50042624  0.2597866   0.58276073\n",
      "  0.64161673  0.42195019  0.8663861   0.65851771  0.91686439  0.97052901\n",
      "  0.80057641  0.84759527]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Check mutual information between continuous variables and log-loss.\n",
    "'''\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "mi = mutual_info_regression(df2[conts], df2[\"logloss\"])\n",
    "mi /= np.max(mi)\n",
    "print(\"\\nMutual Informations: {0}\\n\".format(mi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
